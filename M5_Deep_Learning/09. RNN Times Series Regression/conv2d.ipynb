{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50ad889c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "import itertools \n",
    "import os\n",
    "import sys\n",
    "import scipy.misc\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf9e0958",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def   init  (self):\n",
    "        super(). init  ()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=3) \n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fullyconnected1 = nn.Linear(320, 50) \n",
    "        self.fullyconnected2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2)) \n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fullyconnected1(x))\n",
    "        x = F.dropout(x, training=self.training) \n",
    "        x = self.fullyconnected2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aea14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "def fit_model(epoch,model,data_loader,phase='training',volatile=False): \n",
    "    if phase == 'training':\n",
    "        model.train()\n",
    "    if phase == 'validation': \n",
    "        model.eval() volatile=True\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0\n",
    "        for batch_idx , (data,target) in enumerate(data_loader): \n",
    "        if is_cuda:\n",
    "            data,target = data.cuda(),target.cuda()\n",
    "            data , target = Variable(data,volatile),Variable(target) \n",
    "        if phase == 'training':\n",
    "            optimizer.zero_grad() \n",
    "            output = model(data)\n",
    "            loss = F.null_loss(output,target) \n",
    "            running_loss += F.null_loss(output,target,size_average=False).data[0] \n",
    "            predictions = output.data.max(dim=1,keepdim=True)[1]\n",
    "            running_correct += preds.eq(target.data.view_as(predictions)).cpu().sum() \n",
    "        if phase == 'training':\n",
    "            loss.backward() optimizer.step()\n",
    "            loss = running_loss/len(data_loader.dataset)\n",
    "            accuracy = 100. * running_correct/len(data_loader.dataset) \n",
    "            print(f'{phase} loss is {loss:{5}.{2}} and {phase} accuracy is{running_correct}/{len(data_loader.dataset)}{accuracy:{10}.{4}}') \n",
    "            return loss,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910a518a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18973856",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
