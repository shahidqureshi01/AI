{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mjnuJ19dJV7v"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas   1.1.3\n",
      "Sklearn  0.23.2\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from IPython.display import clear_output\n",
    "import numpy    as np\n",
    "import pandas   as pd\n",
    "import seaborn  as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn  as skl\n",
    "\n",
    "from sklearn import pipeline      # Pipeline\n",
    "from sklearn import preprocessing # OrdinalEncoder, LabelEncoder\n",
    "from sklearn import impute\n",
    "from sklearn import compose\n",
    "from sklearn import model_selection # train_test_split\n",
    "from sklearn import metrics         # accuracy_score, balanced_accuracy_score, plot_confusion_matrix\n",
    "from sklearn import set_config\n",
    "\n",
    "set_config(display='diagram') # Useful for display the pipeline\n",
    "\n",
    "print(\"Pandas  \", pd.__version__)\n",
    "print(\"Sklearn \", skl.__version__) # Try to use 0.24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the dataset\n",
    "- **CLOUD = True**: Download dataset from Kaggle. Necesary for cloud enviroments like COLAB. **Specify your [kaggle credentials](https://www.kaggle.com/docs/api)**.\n",
    "- **CLOUD = False**: Get the dataset from your local machine. **Specify the data path**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv  train.csv\r\n"
     ]
    }
   ],
   "source": [
    "CLOUD = False\n",
    "\n",
    "if CLOUD:\n",
    "    import os\n",
    "    os.environ['KAGGLE_USERNAME'] = \"your_kaggle_username\"\n",
    "    os.environ['KAGGLE_KEY']      = \"your_kaggle_api_key\"  # See https://www.kaggle.com/docs/api\n",
    "    !pip install --upgrade kaggle\n",
    "    !kaggle competitions download -c titanic\n",
    "    DATA_PATH = \"./\"\n",
    "\n",
    "else:\n",
    "    DATA_PATH = \"../../Datasets/Tabular/titanic/\"\n",
    "\n",
    "\n",
    "!ls ../../Datasets/Tabular/titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAy8TnVPJV8S"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame: (891, 11)\n",
      "Test DataFrame:  (418, 10)\n"
     ]
    }
   ],
   "source": [
    "df      = pd.read_csv(DATA_PATH + \"train.csv\", index_col='PassengerId')\n",
    "df_test = pd.read_csv(DATA_PATH + \"test.csv\",  index_col='PassengerId')\n",
    "\n",
    "print(\"Train DataFrame:\", df.shape)\n",
    "print(\"Test DataFrame: \", df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived      0\n",
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age         177\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          0\n",
       "Cabin       687\n",
       "Embarked      2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.isnull().sum()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pclass        0\n",
       "Name          0\n",
       "Sex           0\n",
       "Age          86\n",
       "SibSp         0\n",
       "Parch         0\n",
       "Ticket        0\n",
       "Fare          1\n",
       "Cabin       327\n",
       "Embarked      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df_test.isnull().sum()\n",
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1 (2pts):\n",
    "Extract the title (Mr, Mrs, ... ) from the \"Name\" column.\n",
    "\n",
    "Tips:\n",
    "- split(',')[1] to get the 2nd part, and remove the surnamename\n",
    "- split('.')[0] to get the 1str part, and remove the name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cac1de4ed2d966fcdf707a8bfd131fba",
     "grade": false,
     "grade_id": "cell-d56107842f0f54d2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr\n"
     ]
    }
   ],
   "source": [
    "# CODE HERE get_Title_from_Name funtion\n",
    "# Create this function using lambda (not def)\n",
    "\n",
    "get_Title_from_Name = None\n",
    "\n",
    "# YOUR CODE HERE\n",
    "#get_Title_from_Name.split(',')[1].split('.')[0]\n",
    "def get_Title_from_Name(name):\n",
    "    return name.split(',')[1].split('.')[0]\n",
    "#raise NotImplementedError()\n",
    "\n",
    "df['Title']      = df['Name'].map(get_Title_from_Name)\n",
    "df_test['Title'] = df_test['Name'].map(get_Title_from_Name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23c4d567e5fb4f4b69a001df14c6f7c",
     "grade": true,
     "grade_id": "cell-f3d989a17018344b",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ceb1adacc335>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Mr\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Mrs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Miss\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Mr\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert df['Title'].values[0] == \"Mr\"\n",
    "assert df['Title'].values[1] == \"Mrs\"\n",
    "assert df['Title'].values[2] == \"Miss\"\n",
    "\n",
    "assert df_test['Title'].values[0] == \"Mr\"\n",
    "assert df_test['Title'].values[1] == \"Mrs\"\n",
    "assert df_test['Title'].values[414] == \"Dona\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2 (1pts):\n",
    "Apply the title_dictionary to get a better information about the title. You have to overwrite the Title variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "da7233548e7218eded680b5edb7963de",
     "grade": false,
     "grade_id": "cell-5c6a842c812fafda",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Miss\n"
     ]
    }
   ],
   "source": [
    "# Use map to apply the prevous dict\n",
    "\n",
    "# df[\"Title\"] = df.replace\n",
    "# df_test[\"Title\"] =\n",
    "\n",
    "# YOUR CODE HERE\n",
    "df[\"Title\"] = df[\"Title\"].replace(title_dictionary)\n",
    "df_test[\"Title\"] = df_test[\"Title\"].replace(title_dictionary)\n",
    "print(df['Title'].values[417])\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "96a09f1cde63b704ff2f391309c30690",
     "grade": true,
     "grade_id": "cell-669f5a637e57e835",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-319aac91d420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m886\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Officer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m417\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"Master\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert df['Title'].values[886] == \"Officer\"\n",
    "assert df_test['Title'].values[417] == \"Master\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTINAL (0pts):\n",
    "Try to extract some information from the feature **Ticket**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "892                 330911\n",
       "893                 363272\n",
       "894                 240276\n",
       "895                 315154\n",
       "896                3101298\n",
       "               ...        \n",
       "1305             A.5. 3236\n",
       "1306              PC 17758\n",
       "1307    SOTON/O.Q. 3101262\n",
       "1308                359309\n",
       "1309                  2668\n",
       "Name: Ticket, Length: 418, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Ticket']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise OPTIONAL (0pts):\n",
    "Try to extract some information from the feature **Cabin**. Search on Internet if that colum has some kind of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId\n",
       "892      NaN\n",
       "893      NaN\n",
       "894      NaN\n",
       "895      NaN\n",
       "896      NaN\n",
       "        ... \n",
       "1305     NaN\n",
       "1306    C105\n",
       "1307     NaN\n",
       "1308     NaN\n",
       "1309     NaN\n",
       "Name: Cabin, Length: 418, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['Cabin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "For X data, notice that...\n",
    "- We drop Survived because is the target variable\n",
    "- We drop Name because we have extracted the Title: Mr, Mrs, ...\n",
    "- We drop Ticket because it has no information -> see df.Ticket.nunique()\n",
    "- We drop Cabin because it has a lot of missings (77% are missings)\n",
    "\n",
    "Then, we identify **numerical** variables and **categorical** variables,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop(columns=[\"Survived\", 'Name', 'Ticket', 'Cabin']) # X DATA (WILL BE TRAIN+VALID DATA)\n",
    "y = df[\"Survived\"] # 0 = No, 1 = Yes\n",
    "\n",
    "x_test = df_test.drop(columns=['Name', 'Ticket', 'Cabin']) # # X_TEST DATA (NEW DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numerical features:\n",
      " ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']\n",
      "\n",
      "Categorical features:\n",
      " ['Sex', 'Embarked', 'Title']\n"
     ]
    }
   ],
   "source": [
    "cat_vars  = ['Sex', 'Embarked', 'Title']         # x.select_dtypes(include=[object]).columns.values.tolist()\n",
    "num_vars  = ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age'] # x.select_dtypes(exclude=[object]).columns.values.tolist()\n",
    "\n",
    "print(\"\\nNumerical features:\\n\", num_vars)\n",
    "print(\"\\nCategorical features:\\n\", cat_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3 (2pts):\n",
    "Create a **ColumnTransformer for Tree Models**. You need to create 2 pipelines (one for numerical and other for categories). Remember:\n",
    "- Categorical pipeline: Some SimpleImputer -> Some Encoder\n",
    "- Numerical pipeline: Some SimpleImputer -> NO Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4a99fc5ecc693dc549b0e1560c568eea",
     "grade": false,
     "grade_id": "cell-c607e75fb38ea248",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"aac15799-a390-4b51-a5cd-779f6b013a4d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"aac15799-a390-4b51-a5cd-779f6b013a4d\">ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='missing',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['Sex', 'Embarked', 'Title'])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5aa15e05-677d-442f-b8db-ebfeb803a264\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5aa15e05-677d-442f-b8db-ebfeb803a264\">num</label><div class=\"sk-toggleable__content\"><pre>['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0e25d37b-7395-49b0-a6d5-e0ff0acb98c7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0e25d37b-7395-49b0-a6d5-e0ff0acb98c7\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ad5cc739-dcdc-40eb-b75e-baf1b6f47a94\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ad5cc739-dcdc-40eb-b75e-baf1b6f47a94\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"2e866bad-d318-4dcc-bd3d-4f6ede00ab9b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"2e866bad-d318-4dcc-bd3d-4f6ede00ab9b\">cat</label><div class=\"sk-toggleable__content\"><pre>['Sex', 'Embarked', 'Title']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0a70d224-d1c2-4e5f-97f4-5daaf2b8ec6d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0a70d224-d1c2-4e5f-97f4-5daaf2b8ec6d\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value='missing', strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ff8a5088-7e51-4687-8721-a27c9af74b6e\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ff8a5088-7e51-4687-8721-a27c9af74b6e\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "ColumnTransformer(transformers=[('num',\n",
       "                                 Pipeline(steps=[('imputer', SimpleImputer()),\n",
       "                                                 ('scaler', StandardScaler())]),\n",
       "                                 ['Pclass', 'SibSp', 'Parch', 'Fare', 'Age']),\n",
       "                                ('cat',\n",
       "                                 Pipeline(steps=[('imputer',\n",
       "                                                  SimpleImputer(fill_value='missing',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('onehot',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['Sex', 'Embarked', 'Title'])])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "num_preprocessing = pipeline.Pipeline(steps=[\n",
    "  # Some SimpleImputer here\n",
    "])\n",
    "\n",
    "cat_preporcessing = pipeline.Pipeline(steps=[\n",
    "  # Some SimpleImputer here\n",
    "  # Some Encoder here. Remember to handle_unknown\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_preprocessing, num_vars),\n",
    "    ('cat', cat_preporcessing, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "tree_prepro\n",
    "\"\"\";\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from sklearn.impute import SimpleImputer\n",
    "from  sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "num_preprocessing = pipeline.Pipeline(steps=[\n",
    "  # Some SimpleImputer here\n",
    "    ('imputer', impute.SimpleImputer(strategy='mean', add_indicator=False)), # mean, median\n",
    "    ('scaler', preprocessing.StandardScaler()) \n",
    "])\n",
    "\n",
    "cat_preporcessing = pipeline.Pipeline(steps=[\n",
    "  # Some SimpleImputer here\n",
    "  # Some Encoder here. Remember to handle_unknown\n",
    "    ('imputer', impute.SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', preprocessing.OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "tree_prepro = compose.ColumnTransformer(transformers=[\n",
    "    ('num', num_preprocessing, num_vars),\n",
    "    ('cat', cat_preporcessing, cat_vars),\n",
    "], remainder='drop') # Drop other vars not specified in num_vars or cat_vars\n",
    "\n",
    "tree_prepro\n",
    "#raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "00bde840843413a4f57c4480f8930ef0",
     "grade": true,
     "grade_id": "cell-e636558135fb5975",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_4_treeModels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-864c4e73e803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_prepro\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;32mis\u001b[0m \u001b[0mcompose\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_column_transformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mColumnTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_4_treeModels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_4_treeModels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_4_treeModels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcat_4_treeModels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_4_treeModels' is not defined"
     ]
    }
   ],
   "source": [
    "assert type(tree_prepro)      is compose._column_transformer.ColumnTransformer\n",
    "assert type(num_4_treeModels) is pipeline.Pipeline\n",
    "assert type(cat_4_treeModels) is pipeline.Pipeline\n",
    "assert len(num_4_treeModels) == 1\n",
    "assert len(cat_4_treeModels) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4 (1pts):\n",
    "1. Complete the diccionary with some Tree Models.\n",
    "2. Then we put each model in a Pipeline where:\n",
    "   - first is the prepocessing with the column Transformer\n",
    "   - Then is the Tree model\n",
    "3. Display the fullpipeline of the LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-4942c4a5fb37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m  \u001b[0;32mimport\u001b[0m \u001b[0menable_hist_gradient_boosting\u001b[0m \u001b[0;31m# Necesary for HistGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m      \u001b[0;32mimport\u001b[0m \u001b[0mHistGradientBoostingClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m               \u001b[0;32mimport\u001b[0m \u001b[0mXGBClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mlightgbm\u001b[0m              \u001b[0;32mimport\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcatboost\u001b[0m              \u001b[0;32mimport\u001b[0m \u001b[0mCatBoostClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree          import DecisionTreeClassifier\n",
    "from sklearn.ensemble      import RandomForestClassifier\n",
    "from sklearn.ensemble      import ExtraTreesClassifier\n",
    "from sklearn.ensemble      import AdaBoostClassifier\n",
    "from sklearn.ensemble      import GradientBoostingClassifier\n",
    "from sklearn.experimental  import enable_hist_gradient_boosting # Necesary for HistGradientBoostingClassifier\n",
    "from sklearn.ensemble      import HistGradientBoostingClassifier\n",
    "from xgboost               import XGBClassifier\n",
    "from lightgbm              import LGBMClassifier\n",
    "from catboost              import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f23af11f3af791efa5687477c0a4c9d6",
     "grade": false,
     "grade_id": "cell-76a3be8223730c5a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-51-c3f4ee6f433d>, line 40)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-51-c3f4ee6f433d>\"\u001b[0;36m, line \u001b[0;32m40\u001b[0m\n\u001b[0;31m    tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Extra Trees\":\n",
    "  \"Random Forest\":\n",
    "  \"AdaBoost\":\n",
    "  \"Skl GBM\":\n",
    "  \"Skl HistGBM\":\n",
    "  \"XGBoost\":\n",
    "  \"LightGBM\":\n",
    "  \"CatBoost\":\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "tree_classifiers[\"LightGBM\"]\n",
    "\"\"\";\n",
    "\n",
    "\n",
    "# YOUR CODE HERE\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "tree_classifiers = {\n",
    "  \"Decision Tree\": DecisionTreeClassifier(),\n",
    "  \"Extra Trees\": ExtraTreesClassifier(n_estimators=100, random_state=0),\n",
    "  \"Random Forest\": RandomForestClassifier(),\n",
    "  \"AdaBoost\": AdaBoostClassifier(),\n",
    "  \"Skl GBM\": GradientBoostingClassifier(),\n",
    "  \"Skl HistGBM\": HistGradientBoostingClassifier(),\n",
    "  \"XGBoost\": XGBClassifier(),\n",
    "  \"LightGBM\": LGBMClassifier(),\n",
    "  \"CatBoost\": CatBoostClassifier(verbose=0, n_estimators=100)\n",
    "\n",
    "#raise NotImplementedError()\n",
    "\n",
    "tree_classifiers = {name: pipeline.make_pipeline(tree_prepro, model) for name, model in tree_classifiers.items()}\n",
    "\n",
    "tree_classifiers[\"LightGBM\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2355552b3ce823e44fdaea06394e054c",
     "grade": true,
     "grade_id": "cell-d4744022b37e2e9b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "for pipe in tree_classifiers.values():\n",
    "    assert type(pipe) is pipeline.Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5 (3pts):\n",
    "Define a simple split validation strategy with:\n",
    "- 80% for train\n",
    "- 20% for validation\n",
    "- With stratification\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "deletable": false,
    "id": "kY1uWk6-OcLw",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e48597a78f468a95abf116052e9f68e6",
     "grade": false,
     "grade_id": "cell-64f17e0d448bca7e",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "3562463f-3197-424c-dc82-b07ad579e9cc"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "x_train, x_val, y_train, y_val = model_selection.train_test_split(\n",
    "    # CODE HERE\n",
    ")\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "\"\"\"\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # FOR EVERY PIPELINE (PREPRO + MODEL) -> TRAIN WITH TRAIN DATA (x_train)\n",
    "    \n",
    "    # GET PREDICTIONS USING x_val\n",
    "    pred = # CODE HERE\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "                              \n",
    "                              \n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dde6f91a6185745a813882e0c1f997bc",
     "grade": true,
     "grade_id": "cell-af27b33fe88ad384",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 (3pts):\n",
    "Define a 10 Fold cross validation strategy with:\n",
    "- With stratification\n",
    "- shuffle=True\n",
    "- random_state=0\n",
    "\n",
    "And train all the models in a for loop.\n",
    "\n",
    "Tip you can use **[cross_val_predict](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html)** for both training and predict with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b9238f7916249fc81179a78b5492e5d4",
     "grade": false,
     "grade_id": "cell-37bf16dc25b43732",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "skf = model_selection.StratifiedKFold(\n",
    "    # CODE HERE\n",
    ")\n",
    "\"\"\"\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results = pd.DataFrame({'Model': [], 'Accuracy': [], 'Bal Acc.': [], 'Time': []})\n",
    "\n",
    "\"\"\"\n",
    "for model_name, model in tree_classifiers.items():\n",
    "    start_time = time.time()\n",
    "        \n",
    "    # TRAIN AND GET PREDICTIONS USING cross_val_predict() and x,y\n",
    "    pred = # CODE HERE\n",
    "\n",
    "    total_time = time.time() - start_time\n",
    "\n",
    "    results = results.append({\"Model\":    model_name,\n",
    "                              \"Accuracy\": metrics.accuracy_score(y_val, pred)*100,\n",
    "                              \"Bal Acc.\": metrics.balanced_accuracy_score(y_val, pred)*100,\n",
    "                              \"Time\":     total_time},\n",
    "                              ignore_index=True)\n",
    "                              \n",
    "                              \n",
    "\"\"\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "\n",
    "results_ord = results.sort_values(by=['Accuracy'], ascending=False, ignore_index=True)\n",
    "results_ord.index += 1 \n",
    "results_ord.style.bar(subset=['Accuracy', 'Bal Acc.'], vmin=0, vmax=100, color='#5fba7d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "355f8e8321aae7be679a8d16b25172f2",
     "grade": true,
     "grade_id": "cell-57cc085faad513cf",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert results_ord[\"Accuracy\"].min() > 75\n",
    "assert results_ord[\"Bal Acc.\"].min() > 75\n",
    "assert len(results_ord) == 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.1\n",
    "Train with all data the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "deletable": false,
    "id": "monuuQhHL7B_",
    "nbgrader": {
     "cell_type": "code",
     "checksum": "088ae511ec2eb947de2bff002e75d460",
     "grade": false,
     "grade_id": "cell-031a656e1e811717",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# best_model = tree_classifiers[\"SELECT MY BEST MODEL HERE\"]\n",
    "\n",
    "# Fit best model with all data\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.2 (2pts)\n",
    "With your best model, generate the predicitions for test data (x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "031ab122b02b5833236370a53d148daf",
     "grade": false,
     "grade_id": "cell-44b93a0dbd4eb6fc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# test_pred = # Get the predictions for x_test\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "180b37cf4a0276bdf509220b1706a8aa",
     "grade": true,
     "grade_id": "cell-a29fc8d24284520e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert len(test_pred) == 418\n",
    "assert np.unique(test_pred).tolist() == [0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7.3\n",
    "\n",
    "Submit to kaggle.\n",
    "\n",
    "- You can use the kaggle command line app. Check https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame(test_pred, index=x_test.index, columns=[\"Survived\"])\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"sub.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kaggle competitions submit -c titanic -f sub.csv -m \"My submission message\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "Titanic LogReg.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "name": "seminar13_optional_practice_trees_titanic.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
