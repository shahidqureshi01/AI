{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "floating-fiction",
   "metadata": {},
   "source": [
    "# Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "funky-burning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"import spacy\\nimport en_core_web_sm\\n\\n%load_ext nb_black\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\";\n",
       "                var nbb_formatted_code = \"import spacy\\nimport en_core_web_sm\\n\\n%load_ext nb_black\\n\\nnlp = spacy.load(\\\"en_core_web_sm\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "%load_ext nb_black\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "closed-water",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\\ndoc = nlp(u\\\"Hello, world. Antonio is learning Python.\\\")\";\n",
       "                var nbb_formatted_code = \"# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\\ndoc = nlp(u\\\"Hello, world. Antonio is learning Python.\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Process sentences 'Hello, world. Antonio is learning Python.' using spaCy\n",
    "doc = nlp(u\"Hello, world. Antonio is learning Python.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-covering",
   "metadata": {},
   "source": [
    "## Get tokens and sentences\n",
    "\n",
    "#### What is a Token?\n",
    "A token is a single chopped up element of the sentence, which could be a word or a group of words to analyse. The task of chopping the sentence up is called \"tokenisation\".\n",
    "\n",
    "Example: The following sentence can be tokenised by splitting up the sentence into individual words.\n",
    "\n",
    "\t\"Antonio is learning Python!\"\n",
    "\t[\"Antonio\",\"is\",\"learning\",\"Python!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "painted-oxford",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "Hello, world.\n",
      "Antonio is learning Python.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"# Get first token of the processed document\\ntoken = doc[0]\\nprint(token)\\n\\n# Print sentences (one sentence per line)\\nfor sent in doc.sents:\\n    print(sent)\";\n",
       "                var nbb_formatted_code = \"# Get first token of the processed document\\ntoken = doc[0]\\nprint(token)\\n\\n# Print sentences (one sentence per line)\\nfor sent in doc.sents:\\n    print(sent)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get first token of the processed document\n",
    "token = doc[0]\n",
    "print(token)\n",
    "\n",
    "# Print sentences (one sentence per line)\n",
    "for sent in doc.sents:\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-america",
   "metadata": {},
   "source": [
    "## Part of speech tags\n",
    "\n",
    "#### What is a Speech Tag?\n",
    "A speech tag is a context sensitive description of what a word means in the context of the whole sentence.\n",
    "More information about the kinds of speech tags which are used in NLP can be [found here](http://www.winwaed.com/blog/2011/11/08/part-of-speech-tags/).\n",
    "\n",
    "Examples:\n",
    "\n",
    "1. CARDINAL, Cardinal Number - 1,2,3\n",
    "2. PROPN, Proper Noun, Singular - \"Jan\", \"Javier\", \"Antonio\", \"Italy\"\n",
    "3. INTJ, Interjection - \"Ohhhhhhhhhhh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "regular-carolina",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('INTJ', Hello), ('PUNCT', ,), ('NOUN', world), ('PUNCT', .), ('PROPN', Antonio), ('AUX', is), ('VERB', learning), ('PROPN', Python), ('PUNCT', .)]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"# For each token, print corresponding part of speech tag\\ntags = [(token.pos_, token) for token in doc]\\nprint(tags)\";\n",
       "                var nbb_formatted_code = \"# For each token, print corresponding part of speech tag\\ntags = [(token.pos_, token) for token in doc]\\nprint(tags)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For each token, print corresponding part of speech tag\n",
    "tags = [(token.pos_, token) for token in doc]\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "english-economy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"from spacy import displacy\";\n",
       "                var nbb_formatted_code = \"from spacy import displacy\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "inner-surgeon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e1f9d85ebadc4836a261e1512d67f4c4-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Hello,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">INTJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">world.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">Antonio</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">learning</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">Python.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">npadvmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M220.0,179.0 L228.0,167.0 212.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-1\" stroke-width=\"2px\" d=\"M420,177.0 C420,2.0 750.0,2.0 750.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,179.0 L412,167.0 428,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-2\" stroke-width=\"2px\" d=\"M595,177.0 C595,89.5 745.0,89.5 745.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M595,179.0 L587,167.0 603,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-e1f9d85ebadc4836a261e1512d67f4c4-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M920.0,179.0 L928.0,167.0 912.0,167.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"displacy.render(doc, style='dep')\";\n",
       "                var nbb_formatted_code = \"displacy.render(doc, style=\\\"dep\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style='dep')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "copyrighted-rabbit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Hello, world. Antonio is learning \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Python\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"displacy.render(doc, style = \\\"ent\\\",jupyter = True)\";\n",
       "                var nbb_formatted_code = \"displacy.render(doc, style=\\\"ent\\\", jupyter=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "displacy.render(doc, style = \"ent\",jupyter = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-typing",
   "metadata": {},
   "source": [
    "We have said that dependency structures are represented by directed graphs that satisfy the following constraints:\n",
    "\n",
    "1. There is a single designated root node that has no incoming arcs.\n",
    "\n",
    "2. With the exception of the root node, each vertex has exactly one incoming arc.\n",
    "\n",
    "3. There is a unique path from the root node to each vertex in V.\n",
    "\n",
    "You can inspect the head of each token by invoking the `.head` attribute of a spaCy token:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "premium-violence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "world"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"doc[2]\";\n",
       "                var nbb_formatted_code = \"doc[2]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "remarkable-integration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hello"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"doc[2].head\";\n",
       "                var nbb_formatted_code = \"doc[2].head\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc[2].head"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-character",
   "metadata": {},
   "source": [
    "So how would you search for the root?\n",
    "\n",
    "Since there is a unique path from the root node to each vertex in V, there's only one root node that has no incoming arcs, we can search for the token which have as head itself!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "celtic-armstrong",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n",
      "learning\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"for token in doc:\\n    if token.head == token:\\n        print(token)\";\n",
       "                var nbb_formatted_code = \"for token in doc:\\n    if token.head == token:\\n        print(token)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for token in doc:\n",
    "    if token.head == token:\n",
    "        print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-ground",
   "metadata": {},
   "source": [
    "As expected, since there were two sentences in the doc, we got two roots.\n",
    "\n",
    "We can also build a function that, given a spaCy token, gives the path till the root:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "threaded-breast",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Define a function to find the path to the root of each word in a sentence\\ndef path_to_the_root(token):\\n    if token.head == token:\\n        return\\n    else: \\n        print(f'{token.head}->{token}')\\n        get_root(token.head)\";\n",
       "                var nbb_formatted_code = \"# Define a function to find the path to the root of each word in a sentence\\ndef path_to_the_root(token):\\n    if token.head == token:\\n        return\\n    else:\\n        print(f\\\"{token.head}->{token}\\\")\\n        get_root(token.head)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to find the path to the root of each word in a sentence\n",
    "def path_to_the_root(token):\n",
    "    if token.head == token:\n",
    "        return\n",
    "    else: \n",
    "        print(f'{token.head}->{token}')\n",
    "        get_root(token.head)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "united-smooth",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learning->Antonio\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"path_to_the_root(doc[4])\";\n",
       "                var nbb_formatted_code = \"path_to_the_root(doc[4])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_the_root(doc[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ca623d",
   "metadata": {},
   "source": [
    "## Embeddings \n",
    "\n",
    "An embedding is a fixed sizes numerical vector that attempts to encode some semantic meaning of the word or sentence it is encoding. The distributional hypothesis is usually the concept behind most embeddings. This hypothesis states that words which often have the same neighboring words tend to be semantically similar. For example if 'football' and 'basketball' usually appear close the word 'play' we assume that they will be semantically similar. An algorithm that is based on this concept is Word2Vec. A common way of obtaining sentence embeddings is to average the word embeddings inside the sentence and use that average as the representation of the whole sentence. \n",
    "\n",
    "- In spacy every token has its embedding.\n",
    "- It is under the attribute 'vector'.\n",
    "- In spacy embeddings are of size 96 or 128.\n",
    "\n",
    "\n",
    "Obtain the embeddings of all the tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6e379590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-7.2769040e-01, -6.5467489e-01,  3.4545848e-01, -1.3211331e+00,\n",
      "        3.8329524e-01,  1.6095481e+00,  4.0210347e+00,  2.7814531e+00,\n",
      "        4.2899132e+00,  3.5156488e+00,  2.2655723e+00, -3.0103502e+00,\n",
      "        2.2251215e+00,  8.6697561e-01,  2.1651659e+00,  3.6331279e+00,\n",
      "        3.2939694e+00,  2.4538593e+00, -1.0154125e-01, -6.6271687e-01,\n",
      "        4.4526100e+00, -4.8443186e-01,  1.1999233e+00,  5.0796497e-01,\n",
      "        2.2959852e+00,  1.2470492e+00, -7.6798129e-01,  2.8587785e+00,\n",
      "       -8.9219618e-01, -6.2705553e-01, -1.5051959e+00, -6.2507683e-01,\n",
      "       -2.0319629e+00, -1.5944457e+00,  1.2612584e+00,  8.6164564e-01,\n",
      "        4.2223060e-01,  8.7489688e-01, -2.7122064e+00, -1.7095518e+00,\n",
      "        4.4883766e+00,  2.1760783e+00, -2.3332880e+00,  2.7503304e+00,\n",
      "        9.2422390e-01, -2.2956979e-01, -1.6059887e+00,  3.3145928e+00,\n",
      "       -2.3757935e+00, -2.1428237e+00, -3.9303966e+00,  1.0370404e+00,\n",
      "       -1.9046664e-04,  1.9203992e+00, -6.8202686e-01, -2.1523390e+00,\n",
      "       -1.9181170e+00, -2.2858567e+00, -3.9379473e+00,  1.1237047e+00,\n",
      "       -1.7649655e+00,  7.7865487e-01, -6.8347263e-01,  3.3422742e+00,\n",
      "       -2.6190561e-01,  2.2855914e+00,  2.1553602e+00,  1.5810817e+00,\n",
      "        4.8113590e-01, -9.9076563e-01, -3.6769340e+00, -9.9577600e-01,\n",
      "        9.8864371e-01,  3.8406652e-01,  5.8278146e+00,  1.2665319e-01,\n",
      "       -1.8373647e+00, -1.7701612e+00, -8.1970644e-01,  2.5923052e-01,\n",
      "       -7.1623212e-01, -2.6230819e+00, -1.7886243e+00,  2.2979321e+00,\n",
      "       -4.5315733e+00, -2.3628335e+00,  3.8100979e+00,  1.0520916e+00,\n",
      "       -8.1554824e-01,  1.1026633e-01, -6.6100240e-01,  1.9756478e-01,\n",
      "       -3.3751483e+00, -3.7828448e+00, -3.6644015e+00, -3.5085788e+00],\n",
      "      dtype=float32), array([-1.6218868 , -0.7955526 , -1.6763616 , -3.1789165 , -0.8494856 ,\n",
      "       -1.9115827 , -1.0004684 ,  1.7871426 , -3.0960374 ,  0.44225723,\n",
      "       -0.23923202,  0.79605275,  1.004439  ,  2.0657907 , -3.046432  ,\n",
      "        3.3212    , -2.278794  ,  2.313822  , -2.4923868 ,  5.4397836 ,\n",
      "       -0.47371095, -0.76654494,  2.132679  , -0.12913996,  3.3426805 ,\n",
      "        0.27242854, -1.4000802 , -2.0211332 , -1.7830014 ,  1.1342556 ,\n",
      "       -0.8736955 , -3.0505075 , -3.2905452 , -3.1483383 , -0.73021275,\n",
      "        0.60684454,  0.76722944,  1.438887  ,  1.744779  , -1.4604315 ,\n",
      "        4.5974483 ,  0.9538796 ,  3.7353115 , -1.346852  , -0.9985283 ,\n",
      "        1.6233011 , -0.91061956, -1.067732  ,  1.0360003 , -0.02394193,\n",
      "       -1.317999  ,  2.42388   , -1.3417943 ,  0.29354823,  1.3967102 ,\n",
      "       -0.14741606, -1.6517947 ,  1.4225667 ,  1.7235135 ,  1.2530266 ,\n",
      "        3.4052505 ,  3.7858593 ,  0.2497698 , -0.7417065 , -3.2690063 ,\n",
      "        1.2027241 ,  2.7796297 ,  0.7049021 ,  1.9339576 ,  2.2620928 ,\n",
      "        4.2747645 , -0.06149197,  0.30412692, -1.2430336 , -3.0251098 ,\n",
      "       -1.3292348 ,  0.65241426, -0.53246063, -5.020323  ,  0.8955262 ,\n",
      "       -3.4792347 ,  1.7151551 ,  3.504248  , -1.1158193 , -1.5286075 ,\n",
      "        1.2541883 ,  3.1951108 ,  1.5356704 ,  1.865416  , -1.3909875 ,\n",
      "       -2.550941  ,  0.56452924, -3.4927382 ,  2.7735908 , -1.8420475 ,\n",
      "       -2.1504445 ], dtype=float32), array([ 0.0748066 ,  3.1616623 ,  1.3854631 , -2.1181085 ,  1.5449305 ,\n",
      "       -1.5420232 , -0.42500436, -1.7912211 , -1.8980093 ,  2.0626447 ,\n",
      "        0.6015817 ,  1.0890582 ,  2.3294916 , -1.6550949 ,  1.9543393 ,\n",
      "        0.69423246,  3.1256807 , -3.1184247 ,  0.13475662,  4.3906817 ,\n",
      "        3.8662944 , -2.3772755 , -1.9267304 , -1.0420891 ,  2.1542017 ,\n",
      "        0.01362798, -1.1894417 , -1.8063016 ,  1.579056  ,  0.7031364 ,\n",
      "       -2.8912716 ,  1.955954  ,  2.395609  , -1.5253469 ,  0.5741186 ,\n",
      "       -1.9531326 ,  1.5836209 , -0.9854208 ,  1.513922  ,  1.0719838 ,\n",
      "        0.6726978 ,  2.824955  , -0.8159412 ,  1.5888937 ,  2.9147286 ,\n",
      "       -2.627808  , -0.99436784,  0.50225437,  0.68430406, -2.7493937 ,\n",
      "       -2.3875108 ,  0.05637455,  2.103274  ,  0.98887193, -1.1565247 ,\n",
      "        1.8367366 , -1.5821807 , -1.5078651 , -2.5068994 ,  2.0333762 ,\n",
      "        0.7857644 , -1.7676171 , -0.7645055 ,  0.23356992, -3.6309352 ,\n",
      "        0.19325271,  1.1063925 , -1.2819772 , -0.3869825 ,  2.9204788 ,\n",
      "       -0.3009744 ,  1.5455468 ,  0.07453504, -1.1612773 ,  0.26126552,\n",
      "        0.7733704 ,  1.5309863 ,  2.8463423 , -1.3433199 ,  0.02292673,\n",
      "       -0.03973925, -3.2879887 ,  2.5773299 ,  2.6502063 , -3.164537  ,\n",
      "       -0.8049377 ,  1.7403967 ,  0.3198297 ,  0.08456933, -2.412311  ,\n",
      "        0.31774297, -1.2165816 , -2.6255317 , -1.9863458 , -1.5592166 ,\n",
      "       -0.9749793 ], dtype=float32), array([-0.5023417 , -3.0712037 , -3.1699085 , -1.6035476 ,  0.46524823,\n",
      "       -1.9536225 ,  2.1710055 ,  0.8711204 ,  0.26831877, -3.7858486 ,\n",
      "       -1.2126122 , -5.8171597 ,  2.6738396 ,  2.0623105 , -3.1565623 ,\n",
      "       -3.2014325 , -1.7991084 , -2.5246832 , -1.461163  ,  2.1663246 ,\n",
      "        3.015803  , -0.7782768 ,  4.5098286 ,  3.3663483 ,  0.16676176,\n",
      "        3.2360318 , -2.0497022 , -1.6722622 , -1.7033081 , -1.9730132 ,\n",
      "       -0.1021803 , -0.9699281 ,  0.7717167 , -0.30948454, -1.9337277 ,\n",
      "        0.5469358 , -1.2738212 ,  0.9807547 ,  2.291495  , -0.8382104 ,\n",
      "       -0.90112305, -0.7418355 ,  2.3891852 , -1.8928645 , -0.22343299,\n",
      "       -1.2161269 ,  0.51420766,  0.19463412,  0.735343  ,  2.6809354 ,\n",
      "       -0.5929867 ,  1.7827346 , -0.00645518,  1.5084758 , -1.6714652 ,\n",
      "       -0.41250038, -0.4869293 , -1.3147273 ,  0.27980888, -0.74160373,\n",
      "       -0.10927129,  1.8809046 ,  2.0404022 ,  0.27807423,  1.2665235 ,\n",
      "        1.7103711 , -1.4471684 , -1.4830836 , -1.4298246 ,  1.1965342 ,\n",
      "        1.3748161 ,  1.5490996 ,  0.11120057,  1.7042118 , -2.135522  ,\n",
      "        2.9304266 ,  0.20550275, -0.27758282,  0.2018807 , -0.06792027,\n",
      "       -2.0445933 ,  2.0365314 ,  6.077743  , -3.490012  , -0.15044144,\n",
      "        2.7812316 ,  0.9767577 ,  0.26835245, -0.20082429,  0.942744  ,\n",
      "        0.23369455,  2.6573777 , -2.3439207 ,  2.6614041 ,  0.43746075,\n",
      "       -2.5316803 ], dtype=float32), array([ 0.7469422 ,  1.0642254 ,  1.3627915 ,  0.5402818 ,  3.7314284 ,\n",
      "       -1.3520054 , -0.5750615 ,  0.3454271 , -1.8249189 , -1.5087714 ,\n",
      "        1.7216008 , -0.6957568 , -0.47150958,  1.0774828 , -2.9657092 ,\n",
      "       -1.1478431 , -1.0801625 ,  3.0775838 , -0.3733794 , -1.2594488 ,\n",
      "       -0.07117593, -1.6968178 ,  1.9822433 , -1.9712298 , -1.4421546 ,\n",
      "        0.84917843, -2.4945364 , -2.7336724 ,  2.7436595 ,  0.16236776,\n",
      "       -1.8275445 , -0.5611701 ,  0.81159645, -0.80494475,  3.2819788 ,\n",
      "        0.52842295,  3.2902274 , -0.7513378 ,  1.0981764 , -0.35031652,\n",
      "        2.2588587 ,  0.7813027 ,  2.9989672 , -0.38843125,  1.0353999 ,\n",
      "       -1.2717351 ,  1.574977  ,  3.9341795 , -1.2325709 , -1.8454573 ,\n",
      "        0.8321436 , -0.07097948,  0.3965249 , -0.33426684, -3.3482957 ,\n",
      "        4.848463  ,  3.4938474 ,  2.605425  , -3.0385265 , -1.8868588 ,\n",
      "       -2.1654859 , -2.573423  ,  1.1170545 , -3.016886  ,  0.15397042,\n",
      "        5.7676134 ,  1.3561907 , -0.33575416,  1.1704121 , -0.57323456,\n",
      "       -3.1286793 ,  2.370193  ,  0.8721092 , -1.3436235 ,  3.709125  ,\n",
      "       -0.9114233 ,  0.40986294, -0.14194891, -0.9865125 , -1.9791479 ,\n",
      "        3.0177538 ,  2.1414409 , -1.6850022 , -1.6985633 , -0.3240317 ,\n",
      "       -1.9743848 , -1.232494  ,  0.9326829 ,  0.6003772 , -1.7145505 ,\n",
      "       -0.08675241, -0.71303415, -2.1894958 , -0.30796164, -0.4633045 ,\n",
      "        1.4831694 ], dtype=float32), array([ 3.451985  ,  3.8930626 , -2.174268  , -1.438889  , -0.7201996 ,\n",
      "        3.007729  ,  1.1542597 , -0.8080119 ,  6.048345  ,  2.9148314 ,\n",
      "        0.8389477 ,  0.23439187, -1.8456652 ,  0.15059707,  2.0966601 ,\n",
      "       -0.38325512,  0.32724094, -0.90009356, -0.4473409 , -1.0647602 ,\n",
      "       -0.20494556, -0.9082808 , -3.2567363 ,  0.3732338 ,  2.0059435 ,\n",
      "       -0.9628016 , -2.3726897 , -4.9155493 , -1.9011132 , -0.87935287,\n",
      "        1.2265363 ,  2.0436945 ,  0.65714926, -0.8585391 , -3.0983267 ,\n",
      "       -1.502374  ,  1.2177817 ,  0.6551355 , -4.809058  ,  0.16195424,\n",
      "       -0.254567  , -0.45482022, -1.7174525 , -0.19135952, -0.48803225,\n",
      "        3.1395607 ,  0.9529371 ,  1.7731116 , -2.3873017 , -0.84346294,\n",
      "        4.043976  , -4.406763  ,  3.9104123 , -0.86560047,  5.871607  ,\n",
      "        1.3382428 ,  2.476012  , -0.21588933, -0.60339177,  2.7994738 ,\n",
      "        1.4329786 ,  2.5121453 ,  3.003527  , -1.5421354 ,  0.58222485,\n",
      "       -1.04947   ,  4.8177953 ,  0.36876276,  1.684832  ,  0.00620067,\n",
      "       -0.2739725 , -3.5662882 , -0.7706168 , -0.66113263, -2.3622148 ,\n",
      "        2.1646698 ,  0.25384077,  0.13632862,  1.396147  , -2.604003  ,\n",
      "       -2.499999  ,  2.9770951 , -1.1025763 , -3.247303  ,  2.1612568 ,\n",
      "       -2.9583557 ,  1.0673842 ,  0.8442497 , -1.4849689 ,  1.7593043 ,\n",
      "       -0.07913011, -1.7311621 ,  2.1599283 , -1.7531524 , -1.8478265 ,\n",
      "       -1.8107004 ], dtype=float32), array([ 0.02945515, -3.9033322 , -1.278376  , -0.31984678, -2.8121014 ,\n",
      "       -2.959259  ,  0.120362  ,  0.07680362, -2.941111  , -1.4668553 ,\n",
      "        0.19257331, -1.615835  ,  1.2632949 ,  0.6014043 ,  4.8357186 ,\n",
      "       -1.5070342 , -0.8290478 ,  2.843167  ,  1.2422915 ,  2.2225924 ,\n",
      "       -1.3446852 ,  2.28397   ,  2.1025066 , -0.03793937,  1.2324386 ,\n",
      "        1.2418103 , -0.08052862, -4.1189237 ,  1.5007304 , -1.907599  ,\n",
      "       -0.6515919 ,  0.7068906 ,  2.1170468 ,  1.0130192 , -3.0734863 ,\n",
      "       -2.1456523 ,  0.59775287, -0.7747534 ,  2.6441638 ,  0.2584387 ,\n",
      "       -0.7914618 , -0.6731684 , -3.557638  , -0.6954567 , -0.88296777,\n",
      "        0.44622964, -3.2295082 ,  5.2669573 ,  0.3759788 ,  1.9616253 ,\n",
      "       -4.884966  ,  0.78105944,  0.38534832,  2.2068257 ,  0.15701437,\n",
      "        4.103673  ,  1.153903  , -1.6431013 , -1.7880373 ,  7.910888  ,\n",
      "        2.517152  , -2.1629362 ,  1.8776948 , -1.021273  , -1.5634577 ,\n",
      "        2.113062  , -1.1064419 , -2.0920973 ,  4.538886  , -0.5101235 ,\n",
      "        2.1170554 , -1.7843696 ,  0.7509663 , -2.3523426 , -0.9500898 ,\n",
      "        2.656758  , -0.83028936,  1.8812147 , -1.4902407 , -0.07600224,\n",
      "       -1.7995384 ,  3.603877  , -0.7013914 ,  1.9116035 , -2.3534842 ,\n",
      "        3.818224  , -0.38325024,  1.0528518 , -3.0629406 , -0.7132021 ,\n",
      "        0.8847017 , -1.6249174 ,  2.691053  ,  4.527087  ,  1.2048944 ,\n",
      "       -2.3751912 ], dtype=float32), array([ 0.87424505, -1.4048741 , -0.87942934, -0.14844894,  2.997435  ,\n",
      "        1.2463253 , -2.1996331 ,  4.1610622 , -0.6203312 ,  1.7519531 ,\n",
      "       -0.5389596 , -3.8046987 , -1.4371214 ,  0.14107382,  0.03385919,\n",
      "       -2.3101604 ,  1.5433993 ,  2.0335019 , -3.458452  , -0.94085485,\n",
      "       -0.08569971,  0.7214367 , -0.6169891 ,  0.06208536, -0.1257613 ,\n",
      "        0.68678576, -4.594602  , -2.6583548 , -1.0209675 , -3.8481245 ,\n",
      "       -1.4686834 , -0.31247628,  0.8671098 , -2.694232  ,  1.1315207 ,\n",
      "        2.1040769 ,  2.1645756 ,  0.15881482, -0.79755735, -0.7050321 ,\n",
      "        0.12856264,  0.51178944, -0.23925352,  1.1917862 ,  4.1579638 ,\n",
      "       -1.2041588 , -1.0971587 ,  1.7265043 , -1.5961115 , -0.3504492 ,\n",
      "       -1.0599632 ,  0.6670586 , -0.22908318,  0.4284351 , -3.929777  ,\n",
      "       -0.8231089 ,  1.4383698 , -0.6721336 , -1.8136729 , -1.0703003 ,\n",
      "       -0.8866372 , -2.1440597 ,  0.8478805 , -3.0952942 ,  2.1494293 ,\n",
      "        4.808999  ,  3.383074  , -0.3767575 ,  1.2021332 ,  1.5506501 ,\n",
      "       -2.616799  ,  4.49311   ,  3.0566626 ,  0.19621001,  1.702235  ,\n",
      "       -2.3091605 ,  0.32093772,  2.7945879 , -0.86729836,  0.5222845 ,\n",
      "        3.535831  , -0.46534663,  0.6482332 ,  1.5025172 ,  1.5834894 ,\n",
      "        1.6032716 , -1.0696889 , -0.33284944, -1.9167836 , -0.8073791 ,\n",
      "        1.9417232 ,  0.7291157 ,  0.06742686,  0.89737713,  0.4694338 ,\n",
      "       -3.163525  ], dtype=float32), array([ 3.5682574e-01, -2.4896607e+00, -2.4462039e+00, -2.0971355e+00,\n",
      "       -1.4515615e-01, -2.5084198e+00,  2.2131734e+00, -2.8528128e+00,\n",
      "       -1.5006086e+00, -2.2426133e+00, -4.8665180e+00, -1.4838415e-01,\n",
      "       -1.6465442e+00,  3.2258220e+00, -3.2830586e+00, -7.7241373e-01,\n",
      "       -1.4068558e+00, -3.1215376e-01, -1.3024342e-01,  1.7480648e+00,\n",
      "        5.0188861e+00, -4.1833121e-01,  2.0506487e+00,  4.5736809e+00,\n",
      "        1.0354431e+00,  2.5560946e+00, -4.3845105e-01, -3.0424442e+00,\n",
      "       -5.3479958e-01, -2.1301460e+00,  2.4054906e+00,  1.1455963e+00,\n",
      "        4.7979611e-01,  6.2810117e-01, -1.6251898e+00,  1.1689067e-03,\n",
      "        2.0018470e-01,  4.6971247e-01, -4.5061332e-01, -7.8277004e-01,\n",
      "       -3.1838980e+00, -2.0211885e+00,  1.2987765e+00, -4.4399395e+00,\n",
      "        4.8016346e-01, -3.7913411e+00,  3.7580361e+00, -1.3882153e+00,\n",
      "        7.9049271e-01,  1.4416742e+00, -5.5643022e-01, -2.7438724e-01,\n",
      "       -3.0241832e-01,  1.4224260e+00, -1.2492909e+00,  8.2733512e-02,\n",
      "        1.1085434e+00, -1.1658623e+00,  2.0241353e-01, -2.2140460e+00,\n",
      "       -9.4701922e-01, -4.6048713e-01,  2.0462821e+00, -2.1800151e+00,\n",
      "       -6.9936812e-01,  6.1476916e-01,  2.6036093e-01,  7.2561282e-01,\n",
      "       -8.3223581e-02,  1.5020949e-01,  5.2378517e-01, -4.3730456e-01,\n",
      "       -5.7955492e-01,  1.7727652e+00,  2.6143134e-01,  1.8372180e+00,\n",
      "       -2.4332315e-01,  8.6102486e-01, -6.9459343e-01, -9.8230731e-01,\n",
      "        5.6855255e-01,  2.2991533e+00,  6.4684353e+00, -2.8067150e+00,\n",
      "       -5.0464034e-01,  2.5851221e+00,  3.0889207e-01,  1.7513555e+00,\n",
      "       -1.0546303e-01,  1.9741082e+00, -1.7195113e+00,  1.1802771e+00,\n",
      "        2.6638026e+00,  5.6616678e+00, -1.3926680e+00, -2.1608336e+00],\n",
      "      dtype=float32)]\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"embd = [token.vector for token in doc]\\nprint(embd)\";\n",
       "                var nbb_formatted_code = \"embd = [token.vector for token in doc]\\nprint(embd)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embd = [token.vector for token in doc]\n",
    "print(embd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a96b00",
   "metadata": {},
   "source": [
    "## Semantic similarity \n",
    "\n",
    "To compute the semantic similarity between two sentences, $u$ and $v$, we measure the cossine similarity between the two sentence embeddings. The formula is as follows:\n",
    "\n",
    "$sim(u, v) = \\frac{u \\cdot v}{||u|| ||v||} $\n",
    "\n",
    "\n",
    "Use the following formula to get the semantic similarity betwen the words in doc.\n",
    "Feel free to test it between differente words too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bded54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_sim(u,v):\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-virgin",
   "metadata": {},
   "source": [
    "# Pride and Prejudice analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-danger",
   "metadata": {},
   "source": [
    "We would like to:\n",
    "\n",
    "- Extract the names of all the characters from the book (e.g. Elizabeth, Darcy, Bingley)\n",
    "- Visualize characters' occurences with regards to relative position in the book\n",
    "- Authomatically describe any character from the book\n",
    "- Find out which characters have been mentioned in a context of marriage\n",
    "- Build keywords extraction that could be used to display a word cloud (example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mysterious-remark",
   "metadata": {},
   "source": [
    "To load the text file, it is convinient to decode using the utf-8 standard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "catholic-envelope",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file_name):\n",
    "    with open(file_name, \"r\", encoding=\"utf-8\") as file:\n",
    "        return file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-sentence",
   "metadata": {},
   "source": [
    "### Process full text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-personality",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = read_file(\"data/pride_and_prejudice.txt\")\n",
    "# Process the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-uruguay",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many sentences are in the book (Pride & Prejudice)?\n",
    "\n",
    "# Print sentences from index 10 to index 15, to make sure that we have parsed the correct book\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "illegal-devon",
   "metadata": {},
   "source": [
    "## Find all the personal names\n",
    "\n",
    "[Hint](# \"List doc.ents and check ent.label_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secret-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all the personal names from Pride & Prejudice and count their occurrences.\n",
    "# Expected output is a list in the following form: [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266) ...].\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "def find_character_occurences(doc):\n",
    "    \"\"\"\n",
    "    Return a list of actors from `doc` with corresponding occurences.\n",
    "\n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :return: list of tuples in form\n",
    "        [('elizabeth', 622), ('darcy', 312), ('jane', 286), ('bennet', 266)]\n",
    "    \"\"\"\n",
    "\n",
    "    characters = Counter()\n",
    "    # your code here\n",
    "\n",
    "\n",
    "print(find_character_occurences(processed_text)[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prime-turtle",
   "metadata": {},
   "source": [
    "## Plot characters personal names as a time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spatial-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib Jupyter HACK\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-entity",
   "metadata": {},
   "source": [
    "We can investigate where a particular entity occurs in the text. We can do it just accessing the `.start` attribute of an entity:\n",
    "\n",
    "[Hint](# \"ent.start\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intelligent-technique",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the start positions of person entities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-stanford",
   "metadata": {},
   "source": [
    "So we can create a function that stores all the offsets of every character:\n",
    "   \n",
    "   \n",
    "[Hint](# \"Create a dictionary with the lowered lemmas [ent.lemma_.lower()] and associate a list of all the ent.starts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "centered-bride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot characters' mentions as a time series relative to the position of the actor's occurrence in a book.\n",
    "\n",
    "def get_character_offsets(doc):\n",
    "    \"\"\"\n",
    "    For every character in a `doc` collect all the occurences offsets and store them into a list. \n",
    "    The function returns a dictionary that has actor lemma as a key and list of occurences as a value for every character.\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :return: dict object in form\n",
    "        {'elizabeth': [123, 543, 4534], 'darcy': [205, 2111]}\n",
    "    \"\"\"\n",
    "            \n",
    "    return dict(character_offsets)\n",
    "\n",
    "character_occurences = get_character_offsets(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "professional-medium",
   "metadata": {},
   "outputs": [],
   "source": [
    "character_occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blind-companion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T17:01:35.087781Z",
     "start_time": "2021-03-28T17:01:35.071546Z"
    }
   },
   "source": [
    "[Hint](# \"Use the character offsets for each character as x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of the character occurrences in the whole text\n",
    "NUM_BINS = 20\n",
    "\n",
    "def plot_character_hist(character_offsets, character_label, cumulative=False):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasonable-theology",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_character_hist(character_occurences, \"elizabeth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_character_hist(character_occurences, \"darcy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "smaller-sunset",
   "metadata": {},
   "source": [
    "### Cumulative occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-thermal",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_character_hist(character_occurences, \"elizabeth\", cumulative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-morris",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_character_hist(character_occurences, \"darcy\", cumulative=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intimate-senior",
   "metadata": {},
   "source": [
    "### Spacy parse tree in action\n",
    "\n",
    "[Hint](# \"ent.subtree, token.pos_ == 'ADJ'\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liked-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find words (adjectives) that describe Mr. Darcy.\n",
    "\n",
    "def get_character_adjectives(doc, character_lemma):\n",
    "    \"\"\"\n",
    "    Find all the adjectives related to `character_lemma` in `doc`\n",
    "    \n",
    "    :param doc: Spacy NLP parsed document\n",
    "    :param character_lemma: string object\n",
    "    :return: list of adjectives related to `character_lemma`\n",
    "    \"\"\"\n",
    "    \n",
    "    adjectives = []\n",
    "    for ent in processed_text.ents:\n",
    "        # your code here\n",
    "        pass\n",
    "    \n",
    "     for ent in processed_text.ents:\n",
    "        if ent.lemma_.lower() == character_lemma:\n",
    "            if ent.root.dep_ == 'nsubj':\n",
    "                for child in ent.root.head.children:\n",
    "                    if child.dep_ == 'acomp':\n",
    "                        adjectives.append(child.lemma_)\n",
    "                        \n",
    "    return adjectives\n",
    "\n",
    "print(get_character_adjectives(processed_text, 'darcy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-count",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find words (adjectives) that describe Elizabeth.\n",
    "\n",
    "\n",
    "print(get_character_adjectives(processed_text, 'elizabeth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-collective",
   "metadata": {},
   "source": [
    "For all the dependencies manual: https://nlp.stanford.edu/software/dependencies_manual.pdf\n",
    "\n",
    "`acomp`: adjectival complement\n",
    "*i.e.* an adjectival phrase which functions as the complement (like an object of the verb) e.g. \"She looks very beautiful\": *beautiful* is an adjectival complement of *looks*\n",
    "\n",
    "`nsubj`: nominal subject\n",
    "*i.e.* a noun phrase which is the syntactic subject of a clause. The head of this relation\n",
    "might not always be a verb: when the verb is a copular verb, the root of the clause is the complement of\n",
    "the copular verb, which can be an adjective or noun.\n",
    "*e.g.* \"Clinton defeated Dole\". The relationship is *nsubj(defeated, Clinton)*\n",
    "\n",
    "\"The baby is cute\". The relationship is *nsubj(cute, baby)*.\n",
    "\n",
    "In the code, `.dep_`stands for syntactic dependency, *i.e.* the relation between tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-warrant",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text.ents[30].root.dep_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-crown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T17:09:34.144121Z",
     "start_time": "2021-03-28T17:09:34.132840Z"
    }
   },
   "source": [
    "[Hint](# \"ent.label_, ent.root.head.lemma_\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "happy-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find characters that are 'talking', 'saying', 'doing' the most. Find the relationship between \n",
    "# entities and corresponding root verbs.\n",
    "\n",
    "character_verb_counter = Counter()\n",
    "\n",
    "\n",
    "for ent in processed_text.ents:\n",
    "    if # your code here:\n",
    "        character_verb_counter[ent.text] += 1\n",
    "\n",
    "print(character_verb_counter.most_common(10)) \n",
    "\n",
    "# do the same for talking and doing\n",
    "\n",
    "print(character_verb_counter.most_common(10)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-hawaiian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-28T17:10:42.811139Z",
     "start_time": "2021-03-28T17:10:42.804815Z"
    }
   },
   "source": [
    "[Hint](# \"ent.label_, ent.root.head.pos_\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-organization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find 20 most used verbs\n",
    "verb_counter = Counter()\n",
    "\n",
    "# your code here\n",
    "\n",
    "print(verb_counter.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-familiar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with the most used verb and how many time a character used the verb\n",
    "\n",
    "import pandas as pd\n",
    "verb_characters = {}\n",
    "verb_list = [verb[0] for verb in verb_counter.most_common(20)]\n",
    "for ent in processed_text.ents:\n",
    "    if ent.label_ == 'PERSON' and ent.root.head.lemma_ in verb_list:\n",
    "        # complete the code\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-election",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(verb_characters).transpose().fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "universal-sweet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the less meaningful columns\n",
    "df = df[df.columns[df.sum()>=10]].sort_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.heatmap(df, annot=True, cmap='Blues')\n",
    "df.style.background_gradient(cmap='Blues')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-trace",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57baa5815c940fdaff4d14510622de9616cae602444507ba5d0b6727c008cbd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
